{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZVO91_qZfdb"
      },
      "source": [
        "# üöÄ Hands-On Lecture: Exploring the GitHub API in Python with Google Colab üêç\n",
        "\n",
        "Welcome to the Hands-on lecture on GitHub API magic!  With the power of Python, we‚Äôll unlock new skills to interact with GitHub repositories like true software engineering pros.\n",
        "\n",
        "**What‚Äôs on the Map?**\n",
        "\n",
        "Here‚Äôs what we‚Äôll uncover in this session:\n",
        "\n",
        "  üõ†Ô∏è Building API Superpowers: Dive into exciting use cases, including:\n",
        "\n",
        "*  Fetching and analyzing issues and comments.\n",
        "*  Accessing code and repositories programmatically.\n",
        "*  Exploring advanced operations to automate your workflows and many more.\n",
        "\n",
        "\n",
        "üí° **Why This Matters**\n",
        "\n",
        "Imagine automating tedious tasks, analyzing repository data like a detective, or building tools that integrate directly with GitHub. The GitHub API opens up limitless possibilities for innovation in software engineering. By the end of this session, you‚Äôll have the tools to transform your ideas into powerful automations!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF5bbIfn48PL"
      },
      "source": [
        "## Let's retrieve some trending projects from GitHub\n",
        "\n",
        "GitHub does not allow to collect trending projects through GitHub API. So, we will do web scrapping. Let's see how it is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Eas26Ir46fD",
        "outputId": "d97af178-cff0-4e6f-9f00-5d7b93728b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available time periods: 'daily', 'weekly', 'monthly'\n",
            "https://github.com/trending/python?since=daily&spoken_language_code=en\n",
            "Top 5 Trending Python Projects on GitHub (Daily, Spoken Language: English):\n",
            "\n",
            "Name: benbusby/whoogle-search\n",
            "Description: A self-hosted, ad-free, privacy-respecting metasearch engine\n",
            "Stars: 10,276\n",
            "Repo URL: https://github.com/benbusby/whoogle-search\n",
            "--------------------------------------------------\n",
            "Name: OpenBB-finance/OpenBB\n",
            "Description: Investment Research for Everyone, Everywhere.\n",
            "Stars: 35,438\n",
            "Repo URL: https://github.com/OpenBB-finance/OpenBB\n",
            "--------------------------------------------------\n",
            "Name: AUTOMATIC1111/stable-diffusion-webui\n",
            "Description: Stable Diffusion web UI\n",
            "Stars: 146,149\n",
            "Repo URL: https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
            "--------------------------------------------------\n",
            "Name: make-all/tuya-local\n",
            "Description: Local support for Tuya devices in Home Assistant\n",
            "Stars: 1,583\n",
            "Repo URL: https://github.com/make-all/tuya-local\n",
            "--------------------------------------------------\n",
            "Name: ArchipelagoMW/Archipelago\n",
            "Description: Archipelago Multi-Game Randomizer and Server\n",
            "Stars: 605\n",
            "Repo URL: https://github.com/ArchipelagoMW/Archipelago\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def fetch_trending_python_projects(time_period=\"daily\", spoken_language=\"en\", limit=5):\n",
        "    # Validate the time period\n",
        "    if time_period not in [\"daily\", \"weekly\", \"monthly\"]:\n",
        "        print(\"Invalid time period. Please choose from 'daily', 'weekly', or 'monthly'.\")\n",
        "        return\n",
        "\n",
        "    # Construct the URL with time period and spoken language\n",
        "    url = f\"https://github.com/trending/python?since={time_period}&spoken_language_code={spoken_language}\"\n",
        "    print(url)\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Find repository entries\n",
        "        projects = soup.find_all(\"article\", class_=\"Box-row\")\n",
        "\n",
        "        print(\n",
        "            f\"Top {limit} Trending Python Projects on GitHub ({time_period.capitalize()}, Spoken Language: English):\\n\"\n",
        "        )\n",
        "        for i, project in enumerate(projects[:limit]):  # Limit to the top 'limit' projects\n",
        "            # Extract repository name\n",
        "            repo_name_tag = project.find(\"h2\", class_=\"h3 lh-condensed\").find(\"a\")\n",
        "            repo_name = repo_name_tag.text.strip().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
        "\n",
        "            # Extract repository URL\n",
        "            repo_url = f\"https://github.com{repo_name_tag['href']}\"\n",
        "\n",
        "            # Extract description\n",
        "            description_tag = project.find(\"p\", class_=\"col-9 color-fg-muted my-1 pr-4\")\n",
        "            description = description_tag.text.strip() if description_tag else \"No description provided\"\n",
        "\n",
        "            # Extract stars\n",
        "            stars_tag = project.find(\"a\", href=lambda x: x and x.endswith(\"/stargazers\"))\n",
        "            stars = stars_tag.text.strip() if stars_tag else \"0\"\n",
        "\n",
        "            print(f\"Name: {repo_name}\")\n",
        "            print(f\"Description: {description}\")\n",
        "            print(f\"Stars: {stars}\")\n",
        "            print(f\"Repo URL: {repo_url}\")\n",
        "            print(\"-\" * 50)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Available time periods: 'daily', 'weekly', 'monthly'\")\n",
        "    time_period = \"daily\"\n",
        "    fetch_trending_python_projects(time_period=time_period, spoken_language=\"en\", limit=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVXGsopnbQDB"
      },
      "source": [
        "## üîë Creating a GitHub Classic API Token\n",
        "\n",
        "To interact with GitHub's API, you need a **Personal Access Token (PAT)**, which acts as a secure key for authentication. Here's how you can generate one:\n",
        "\n",
        "### ‚ú® Step-by-Step Guide:  \n",
        "\n",
        "1. **Login to GitHub**: Start by logging into your GitHub account.  \n",
        "2. **Navigate to Settings**:  \n",
        "   - Click on your profile picture in the top-right corner.  \n",
        "   - Select **Settings** from the dropdown menu.  \n",
        "\n",
        "3. **Go to Developer Settings**:  \n",
        "   - Scroll to the bottom of the left-hand menu in the **Settings** page.  \n",
        "   - Click on **Developer Settings**.  \n",
        "\n",
        "4. **Access Personal Access Tokens**:  \n",
        "   - In the **Developer Settings** menu, find the **Personal Access Tokens** section.  \n",
        "   - Select **Token (classic)** from the dropdown.  \n",
        "\n",
        "5. **Generate New Token**:  \n",
        "   - On the top-right corner, click **Generate new token**.  \n",
        "   - From the dropdown, select **Generate new token (classic)**.  \n",
        "\n",
        "6. **Fill Out the Token Form**:  \n",
        "   - **Note**: Add a descriptive name for the token (e.g., *CMPT470 API Token*) to remember why it was created.  \n",
        "   - **Expiration**: Choose a suitable expiration period (e.g., 7 days, 30 days, or custom).  \n",
        "   - **Scopes**: Select the permissions the token will have. For this lecture, I chose following scopes:  \n",
        "     - `repo`  \n",
        "     - `workflow`  \n",
        "     - `user`  \n",
        "     - `audit_log`  \n",
        "     - `project`  \n",
        "\n",
        "7. **Generate and Save Your Token**:  \n",
        "   - Scroll to the bottom and click **Generate Token**.  \n",
        "   - Once generated, **copy the token immediately**. GitHub will not show it again, and you'll need to create a new token it if lost.\n",
        "\n",
        "---\n",
        "\n",
        "Now that you have your GitHub API token, you‚Äôre ready to connect to GitHub programmatically!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40vSNJJTzi6p"
      },
      "source": [
        "## Technique 1: Let's fetch issues from GitHub API and save them in CSV or JSON file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIItnlNXzFrO",
        "outputId": "aaced6b5-a28e-41af-b46f-e3e697a89cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing issues repository: psf/black\n",
            "Finished issues processing: psf/black\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import requests\n",
        "import json\n",
        "\n",
        "REPOSITORIES = [\"psf/black\"]  # targeted repo\n",
        "TOKEN = \"\"  # GitHub Personal Access Token\n",
        "HEADERS = {\"Authorization\": f\"token {TOKEN}\"}  # header for the request\n",
        "# additional params to access specific types of data\n",
        "PARAMS = {\"state\": \"closed\", \"since\": \"2022-01-01T00:00:00Z\", \"sort\": \"updated\"}\n",
        "\n",
        "\n",
        "def fetch_issues(repo, max_pages=2):\n",
        "    csv_file = f'{repo.replace(\"/\", \"-\")}-issues.csv'\n",
        "    json_file = f'{repo.replace(\"/\", \"-\")}-issues.json'\n",
        "    issues_data = []\n",
        "    page_count = 0\n",
        "    url = f\"https://api.github.com/repos/{repo}/issues\"\n",
        "\n",
        "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"ID\", \"State\", \"Title\", \"Body\", \"Labels\", \"Created At\", \"Closed At\"])\n",
        "\n",
        "        while url and page_count < max_pages:\n",
        "            response = requests.get(url, params=PARAMS, headers=HEADERS)\n",
        "            if response.status_code != 200:\n",
        "                raise Exception(f\"Error {response.status_code}: {response.json()}\")\n",
        "\n",
        "            # looping through each issue\n",
        "            for issue in response.json():\n",
        "                if \"pull_request\" not in issue:  # Skip pull requests\n",
        "                    labels = \",\".join(label[\"name\"] for label in issue.get(\"labels\", []))\n",
        "                    body = issue.get(\"body\", \"\")[:10000]\n",
        "                    row = [\n",
        "                        issue[\"number\"],\n",
        "                        issue[\"state\"],\n",
        "                        issue[\"title\"],\n",
        "                        body,\n",
        "                        labels,\n",
        "                        issue[\"created_at\"],\n",
        "                        issue[\"closed_at\"],\n",
        "                    ]\n",
        "                    # saving to csv\n",
        "                    writer.writerow(row)\n",
        "                    issues_data.append(\n",
        "                        {\n",
        "                            \"ID\": issue[\"number\"],\n",
        "                            \"State\": issue[\"state\"],\n",
        "                            \"Title\": issue[\"title\"],\n",
        "                            \"Body\": body,\n",
        "                            \"Labels\": labels,\n",
        "                            \"Created At\": issue[\"created_at\"],\n",
        "                            \"Closed At\": issue[\"closed_at\"],\n",
        "                        }\n",
        "                    )\n",
        "            # fetching all the issues links so that we can go one by one\n",
        "            links = {\n",
        "                rel.split(\"=\")[1]: url.strip(\"<>\")\n",
        "                for link in response.headers.get(\"Link\", \"\").split(\",\")\n",
        "                for url, rel in [link.split(\";\")]\n",
        "            }\n",
        "            url = links.get(\"next\")  # getting the next url to fetch\n",
        "            page_count += 1\n",
        "\n",
        "    # saving it to json\n",
        "    with open(json_file, \"w\", encoding=\"utf-8\") as jf:\n",
        "        json.dump(issues_data, jf, indent=4)\n",
        "\n",
        "\n",
        "for repository in REPOSITORIES:\n",
        "    print(f\"Processing issues repository: {repository}\")\n",
        "    fetch_issues(repository)\n",
        "    print(f\"Finished issues processing: {repository}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Technique 2: Let's fetch issues from GitHub API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetched 5 issues from tensorflow/tensorflow\n",
            "Issue ID: 2832007193\n",
            "Title: inconsistent result of ```tf.raw_ops.Rsqrt``` on CPU and GPU\n",
            "Description: ### Issue type\n",
            "\n",
            "Bug\n",
            "\n",
            "### Have you reproduced the bug with TensorFlow Nightly?\n",
            "\n",
            "Yes\n",
            "\n",
            "### Source\n",
            "\n",
            "binary\n",
            "\n",
            "### TensorFlow version\n",
            "\n",
            "tf 2.18\n",
            "\n",
            "### Custom code\n",
            "\n",
            "Yes\n",
            "\n",
            "### OS platform and distribution\n",
            "\n",
            "Linux Ubuntu 22.04 (google colab)\n",
            "\n",
            "### Mobile device\n",
            "\n",
            "_No response_\n",
            "\n",
            "### Python version\n",
            "\n",
            "3.11\n",
            "\n",
            "### Bazel version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### GCC/compiler version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### CUDA/cuDNN version\n",
            "\n",
            "12.5/9\n",
            "\n",
            "### GPU model and memory\n",
            "\n",
            "Tesla T4\n",
            "\n",
            "### Current behavior?\n",
            "\n",
            "result of ``tf.raw_ops.Rsqrt``` is inconsistent between CPU and GPU\n",
            "\n",
            "### Standalone code to reproduce the issue\n",
            "\n",
            "```shell\n",
            "import tensorflow as tf\n",
            "\n",
            "x_0 = tf.constant([[[1.2031, 0.2168], [0.1177, 0.6758]], \n",
            "                    [[1.8203, 0.9688], [0.8828, 0.0767]]], dtype=tf.bfloat16)\n",
            "\n",
            "with tf.device('CPU:0'):\n",
            "  result_cpu = tf.raw_ops.Rsqrt(x=x_0)\n",
            "  print(\"Output on CPU:\", result_cpu)\n",
            "\n",
            "with tf.device('GPU:0'):\n",
            "  result_gpu = tf.raw_ops.Rsqrt(x=x_0)\n",
            "  print(\"Output on GPU:\", result_gpu)\n",
            "\n",
            "max_abs_diff = tf.reduce_max(tf.abs(result_cpu - result_gpu)).numpy()\n",
            "\n",
            "is_consistent = tf.experimental.numpy.allclose(tf.cast(result_cpu, tf.float32), tf.cast(result_gpu, tf.float32), rtol=1e-3,  atol=1e-2)\n",
            "\n",
            "print(\"Max absolute difference:\", max_abs_diff)\n",
            "print(\"Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3:\", is_consistent.numpy())\n",
            "```\n",
            "\n",
            "### Relevant log output\n",
            "\n",
            "```shell\n",
            "Output on CPU: tf.Tensor(\n",
            "[[[0.910156 2.14062]\n",
            "  [2.92188 1.21875]]\n",
            "\n",
            " [[0.742188 1.01562]\n",
            "  [1.0625 3.60938]]], shape=(2, 2, 2), dtype=bfloat16)\n",
            "\n",
            "Output on GPU: tf.Tensor(\n",
            "[[[0.914062 2.15625]\n",
            "  [2.90625 1.21875]]\n",
            "\n",
            " [[0.738281 1.01562]\n",
            "  [1.0625 3.60938]]], shape=(2, 2, 2), dtype=bfloat16)\n",
            "\n",
            "Max absolute difference: 0.015625\n",
            "\n",
            "Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3: False\n",
            "```\n",
            "Labels: ['type:bug', 'comp:ops', 'TF 2.18']\n",
            "Created At: 2025-02-05T06:12:29Z\n",
            "Comments: 0\n",
            "================================================================================\n",
            "Issue ID: 2829024522\n",
            "Title: inconsistent result of ```tf.raw_ops.Tan``` on CPU and GPU\n",
            "Description: ### Issue type\n",
            "\n",
            "Bug\n",
            "\n",
            "### Have you reproduced the bug with TensorFlow Nightly?\n",
            "\n",
            "Yes\n",
            "\n",
            "### Source\n",
            "\n",
            "binary\n",
            "\n",
            "### TensorFlow version\n",
            "\n",
            "tf 2.18\n",
            "\n",
            "### Custom code\n",
            "\n",
            "Yes\n",
            "\n",
            "### OS platform and distribution\n",
            "\n",
            "Linux Ubuntu 22.04\n",
            "\n",
            "### Mobile device\n",
            "\n",
            "_No response_\n",
            "\n",
            "### Python version\n",
            "\n",
            "3.11\n",
            "\n",
            "### Bazel version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### GCC/compiler version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### CUDA/cuDNN version\n",
            "\n",
            "12.5/9\n",
            "\n",
            "### GPU model and memory\n",
            "\n",
            "Tesla T4\n",
            "\n",
            "### Current behavior?\n",
            "\n",
            "```tf.raw_ops.Tan``` produces inconsistent results between CPU and GPU\n",
            "\n",
            "### Standalone code to reproduce the issue\n",
            "\n",
            "```shell\n",
            "import tensorflow as tf\n",
            "\n",
            "real = tf.constant([1.5634333], dtype=tf.float32)\n",
            "imag = tf.constant([0.020735], dtype=tf.float32)\n",
            "\n",
            "complex_tensor = tf.complex(real, imag)\n",
            "\n",
            "with tf.device('/CPU:0'):\n",
            "    result_cpu = tf.raw_ops.Tan(x=complex_tensor)\n",
            "    print(result_cpu)\n",
            "\n",
            "with tf.device('/GPU:0'):\n",
            "    result_gpu = tf.raw_ops.Tan(x=complex_tensor)\n",
            "    print(result_gpu)\n",
            "\n",
            "##Comparing whole complex numbers\n",
            "max_abs_diff = tf.reduce_max(tf.abs(result_cpu - result_gpu)).numpy()\n",
            "\n",
            "is_cons = tf.experimental.numpy.allclose(result_cpu, result_gpu, rtol=1e-6,  atol=1e-5)\n",
            "\n",
            "print(\"Max absolute difference:\", max_abs_diff)\n",
            "print(\"Consistency check (CPU vs GPU) with atol=1e-5 and rtol=1e-6:\", is_cons.numpy())\n",
            "\n",
            "##Comparing by parts\n",
            "real_part_cpu = tf.math.real(result_cpu)\n",
            "real_part_gpu = tf.math.real(result_gpu)\n",
            "real_part_diff = tf.reduce_max(tf.abs(real_part_cpu - real_part_gpu)).numpy()\n",
            "real_part_cons = tf.experimental.numpy.allclose(real_part_cpu, real_part_gpu, rtol=1e-6,  atol=1e-5)\n",
            "\n",
            "imag_part_cpu = tf.math.imag(result_cpu)\n",
            "imag_part_gpu = tf.math.imag(result_gpu)\n",
            "imag_part_diff = tf.reduce_max(tf.abs(imag_part_cpu - imag_part_gpu)).numpy()\n",
            "imag_part_cons = tf.experimental.numpy.allclose(imag_part_cpu, imag_part_gpu, rtol=1e-6,  atol=1e-5)\n",
            "\n",
            "print(\"Real parts absolute difference:\", real_part_diff)\n",
            "print(\"Real parts Consistency check with atol=1e-5 and rtol=1e-6:\", real_part_cons.numpy())\n",
            "\n",
            "print(\"Imag parts absolute difference:\", imag_part_diff)\n",
            "print(\"Imag parts Consistency check with atol=1e-5 and rtol=1e-6:\", imag_part_cons.numpy())\n",
            "```\n",
            "\n",
            "### Relevant log output\n",
            "\n",
            "```shell\n",
            "tf.Tensor([15.205576+42.834145j], shape=(1,), dtype=complex64)\n",
            "tf.Tensor([15.205605+42.834225j], shape=(1,), dtype=complex64)\n",
            "\n",
            "Max absolute difference: 8.5064334e-05\n",
            "Consistency check (CPU vs GPU) with atol=1e-5 and rtol=1e-6: False\n",
            "\n",
            "Real parts absolute difference: 2.861023e-05\n",
            "Real parts Consistency check with atol=1e-5 and rtol=1e-6: False\n",
            "\n",
            "Imag parts absolute difference: 8.010864e-05\n",
            "Imag parts Consistency check with atol=1e-5 and rtol=1e-6: False\n",
            "```\n",
            "Labels: ['type:bug', 'comp:ops', 'TF 2.18']\n",
            "Created At: 2025-02-04T03:18:15Z\n",
            "Comments: 1\n",
            "================================================================================\n",
            "Issue ID: 2826301913\n",
            "Title: inconsistent result of ```tf.raw_ops.LogSoftmax``` on CPU and GPU\n",
            "Description: ### Issue type\n",
            "\n",
            "Bug\n",
            "\n",
            "### Have you reproduced the bug with TensorFlow Nightly?\n",
            "\n",
            "Yes\n",
            "\n",
            "### Source\n",
            "\n",
            "binary\n",
            "\n",
            "### TensorFlow version\n",
            "\n",
            "tf 2.18\n",
            "\n",
            "### Custom code\n",
            "\n",
            "Yes\n",
            "\n",
            "### OS platform and distribution\n",
            "\n",
            "Linux Ubuntu 22.04 (google colab)\n",
            "\n",
            "### Mobile device\n",
            "\n",
            "_No response_\n",
            "\n",
            "### Python version\n",
            "\n",
            "3.11\n",
            "\n",
            "### Bazel version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### GCC/compiler version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### CUDA/cuDNN version\n",
            "\n",
            "12.5/9\n",
            "\n",
            "### GPU model and memory\n",
            "\n",
            "Tesla T4\n",
            "\n",
            "### Current behavior?\n",
            "\n",
            "result of ``tf.raw_ops.LogSoftmax``` is inconsistent between CPU and GPU\n",
            "\n",
            "### Standalone code to reproduce the issue\n",
            "\n",
            "```shell\n",
            "import tensorflow as tf\n",
            "\n",
            "logits = tf.constant([[0.0664, -2.3906]], dtype=tf.bfloat16)\n",
            "\n",
            "with tf.device('CPU:0'):\n",
            "  result_cpu = tf.raw_ops.LogSoftmax(logits=logits)\n",
            "  print(\"Output on CPU:\", result_cpu)\n",
            "\n",
            "with tf.device('GPU:0'):\n",
            "  result_gpu = tf.raw_ops.LogSoftmax(logits=logits)\n",
            "  print(\"Output on GPU:\", result_gpu)\n",
            "\n",
            "max_abs_diff = tf.reduce_max(tf.abs(result_cpu - result_gpu)).numpy()\n",
            "\n",
            "is_consistent = tf.experimental.numpy.allclose(tf.cast(result_cpu, tf.float32), tf.cast(result_gpu, tf.float32), rtol=1e-3,  atol=1e-2)\n",
            "\n",
            "print(\"Max absolute difference:\", max_abs_diff)\n",
            "print(\"Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3:\", is_consistent.numpy())\n",
            "```\n",
            "\n",
            "### Relevant log output\n",
            "\n",
            "```shell\n",
            "Output on CPU: tf.Tensor([[-0.0825195 -2.53125]], shape=(1, 2), dtype=bfloat16)\n",
            "\n",
            "Output on GPU: tf.Tensor([[-0.0825195 -2.54688]], shape=(1, 2), dtype=bfloat16)\n",
            "\n",
            "Max absolute difference: 0.015625\n",
            "\n",
            "Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3: False\n",
            "```\n",
            "Labels: ['type:bug', 'comp:ops', 'TF 2.18']\n",
            "Created At: 2025-02-03T03:30:58Z\n",
            "Comments: 0\n",
            "================================================================================\n",
            "Issue ID: 2825649807\n",
            "Title: inconsistent result of ```tf.raw_ops.L2Loss``` on CPU and GPU\n",
            "Description: ### Issue type\n",
            "\n",
            "Bug\n",
            "\n",
            "### Have you reproduced the bug with TensorFlow Nightly?\n",
            "\n",
            "Yes\n",
            "\n",
            "### Source\n",
            "\n",
            "binary\n",
            "\n",
            "### TensorFlow version\n",
            "\n",
            "tf 2.18\n",
            "\n",
            "### Custom code\n",
            "\n",
            "Yes\n",
            "\n",
            "### OS platform and distribution\n",
            "\n",
            "Linux Ubuntu 22.04 (google colab)\n",
            "\n",
            "### Mobile device\n",
            "\n",
            "_No response_\n",
            "\n",
            "### Python version\n",
            "\n",
            "3.11\n",
            "\n",
            "### Bazel version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### GCC/compiler version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### CUDA/cuDNN version\n",
            "\n",
            "12.5/9\n",
            "\n",
            "### GPU model and memory\n",
            "\n",
            "Tesla T4\n",
            "\n",
            "### Current behavior?\n",
            "\n",
            "result of ```tw.raw_ops.L2Loss``` is inconsistent between CPU and GPU\n",
            "\n",
            "### Standalone code to reproduce the issue\n",
            "\n",
            "```shell\n",
            "import tensorflow as tf\n",
            "\n",
            "t = tf.constant([\n",
            "    [[0.9922, -1.4922], \n",
            "     [0.0376,  0.1504], \n",
            "     [0.6172,  1.2266]],\n",
            "\n",
            "    [[-0.1387,  1.3047], \n",
            "     [0.3535, -0.0471], \n",
            "     [0.0437,  0.2637]]\n",
            "], dtype=tf.bfloat16)\n",
            "\n",
            "with tf.device('CPU:0'):\n",
            "  result_cpu = tf.raw_ops.L2Loss(t=t)\n",
            "  print(\"Output on CPU:\", result_cpu)\n",
            "\n",
            "with tf.device('GPU:0'):\n",
            "  result_gpu = tf.raw_ops.L2Loss(t=t)\n",
            "  print(\"Output on GPU:\", result_gpu)\n",
            "\n",
            "max_abs_diff = tf.reduce_max(tf.abs(result_cpu - result_gpu)).numpy()\n",
            "\n",
            "is_consistent = tf.experimental.numpy.allclose(tf.cast(result_cpu, tf.float32), tf.cast(result_gpu, tf.float32), rtol=1e-3,  atol=1e-2)\n",
            "\n",
            "print(\"Max absolute difference:\", max_abs_diff)\n",
            "print(\"Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3:\", is_consistent.numpy())\n",
            "```\n",
            "\n",
            "### Relevant log output\n",
            "\n",
            "```shell\n",
            "Output on CPU: tf.Tensor(3.51562, shape=(), dtype=bfloat16)\n",
            "\n",
            "Output on GPU: tf.Tensor(3.53125, shape=(), dtype=bfloat16)\n",
            "\n",
            "Max absolute difference: 0.015625\n",
            "\n",
            "Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3: False\n",
            "```\n",
            "Labels: ['type:bug', 'comp:ops', 'TF 2.18']\n",
            "Created At: 2025-02-02T07:05:17Z\n",
            "Comments: 1\n",
            "================================================================================\n",
            "Issue ID: 2825135479\n",
            "Title: inconsistent result of ```tf.raw_ops.BiasAddGrad``` on CPU and GPU\n",
            "Description: ### Issue type\n",
            "\n",
            "Bug\n",
            "\n",
            "### Have you reproduced the bug with TensorFlow Nightly?\n",
            "\n",
            "Yes\n",
            "\n",
            "### Source\n",
            "\n",
            "binary\n",
            "\n",
            "### TensorFlow version\n",
            "\n",
            "tf 2.18\n",
            "\n",
            "### Custom code\n",
            "\n",
            "Yes\n",
            "\n",
            "### OS platform and distribution\n",
            "\n",
            "Linux Ubuntu 22.04\n",
            "\n",
            "### Mobile device\n",
            "\n",
            "_No response_\n",
            "\n",
            "### Python version\n",
            "\n",
            "3.11\n",
            "\n",
            "### Bazel version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### GCC/compiler version\n",
            "\n",
            "_No response_\n",
            "\n",
            "### CUDA/cuDNN version\n",
            "\n",
            "12.5/9\n",
            "\n",
            "### GPU model and memory\n",
            "\n",
            "Tesla T4\n",
            "\n",
            "### Current behavior?\n",
            "\n",
            "```tf.raw_ops.BiasAddGrad``` produces inconsistent results between CPU and GPU\n",
            "\n",
            "### Standalone code to reproduce the issue\n",
            "\n",
            "```shell\n",
            "import tensorflow as tf\n",
            "\n",
            "out_backprop = tf.constant([\n",
            "    [\n",
            "        [\n",
            "            [[ 0.2207,  2.1094], [-0.3730, -1.0625], [ 1.7031,  0.7148]], \n",
            "            [[ 1.5078, -0.6719], [-0.6367,  0.5039], [-2.3281,  0.5078]]\n",
            "        ],\n",
            "        [\n",
            "            [[-0.3574,  0.0461], [ 2.3750, -2.9688], [-0.5703, -2.0156]],\n",
            "            [[ 0.8125,  1.7656], [-0.9570,  0.6250], [-0.6914, -0.4746]]\n",
            "        ],\n",
            "        [\n",
            "            [[-0.3750, -0.7383], [ 0.3691,  0.4570], [ 1.1641,  0.2715]],\n",
            "            [[-1.2969, -0.9844], [-0.4863,  1.0938], [-1.4297,  0.8086]]\n",
            "        ]\n",
            "    ],\n",
            "    [\n",
            "        [\n",
            "            [[ 0.3730,  0.8477], [-0.3887,  1.2266], [ 0.0859, -0.5742]],\n",
            "            [[-0.7383, -0.2432], [-0.7578, -0.8281], [-0.1660, -0.9336]]\n",
            "        ],\n",
            "        [\n",
            "            [[ 1.4297,  0.6797], [-1.6172,  0.4941], [-0.3047, -0.3711]],\n",
            "            [[-0.6250, -0.7617], [ 0.9453,  0.1064], [ 1.4062, -2.9531]]\n",
            "        ],\n",
            "        [\n",
            "            [[-1.4297, -0.1387], [ 0.0625,  1.0469], [-0.1953,  1.6406]],\n",
            "            [[-0.3047,  0.5117], [ 1.8125,  1.1797], [-0.8789, -0.4688]]\n",
            "        ]\n",
            "    ]\n",
            "], dtype=tf.bfloat16)\n",
            "\n",
            "with tf.device('CPU:0'):\n",
            "  result_cpu = tf.raw_ops.BiasAddGrad(out_backprop=out_backprop, data_format=\"NCHW\")\n",
            "  print(\"BiasAddGrad Output on CPU:\", result_cpu)\n",
            "\n",
            "with tf.device('GPU:0'):\n",
            "  result_gpu = tf.raw_ops.BiasAddGrad(out_backprop=out_backprop, data_format=\"NCHW\")\n",
            "  print(\"BiasAddGrad Output on GPU:\", result_gpu)\n",
            "\n",
            "max_abs_diff = tf.reduce_max(tf.abs(result_cpu - result_gpu)).numpy()\n",
            "\n",
            "is_consistent = tf.experimental.numpy.allclose(tf.cast(result_cpu, tf.float32), tf.cast(result_gpu, tf.float32), rtol=1e-3,  atol=1e-2)\n",
            "\n",
            "print(\"Max absolute difference:\", max_abs_diff)\n",
            "print(\"Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3:\", is_consistent.numpy())\n",
            "```\n",
            "\n",
            "### Relevant log output\n",
            "\n",
            "```shell\n",
            "BiasAddGrad Output on CPU: tf.Tensor([0.09375 -3.96875 1.70312], shape=(3,), dtype=bfloat16)\n",
            "\n",
            "BiasAddGrad Output on GPU: tf.Tensor([0.078125 -4 1.70312], shape=(3,), dtype=bfloat16)\n",
            "\n",
            "Max absolute difference: 0.03125\n",
            "Consistency check (CPU vs GPU) with atol=1e-2 and rtol=1e-3: False\n",
            "```\n",
            "Labels: ['stat:awaiting tensorflower', 'type:bug', 'comp:ops', 'TF 2.18']\n",
            "Created At: 2025-02-01T10:43:06Z\n",
            "Comments: 4\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# GitHub API endpoint for fetching issues from a public repository\n",
        "repo_owner = \"tensorflow\"  # Change to any repo you want\n",
        "repo_name = \"tensorflow\"\n",
        "api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/issues\"\n",
        "\n",
        "# Define parameters to filter issues\n",
        "TOKEN = \"\"  # GitHub Personal Access Token\n",
        "params = {\"state\": \"open\", \"labels\": \"type:bug\", \"per_page\": 5}  # Number of issues to fetch\n",
        "\n",
        "# Add headers (GitHub API requires a user-agent)\n",
        "headers = {\"Accept\": \"application/vnd.github.v3+json\", \"Authorization\": f\"token {TOKEN}\"}  # add toke\n",
        "\n",
        "# Send request to GitHub API\n",
        "response = requests.get(api_url, headers=headers, params=params)\n",
        "\n",
        "# Process the response\n",
        "if response.status_code == 200:\n",
        "    issues = response.json()\n",
        "    print(f\"Fetched {len(issues)} issues from {repo_owner}/{repo_name}\")\n",
        "\n",
        "    # Extract relevant fields\n",
        "    for issue in issues:\n",
        "        print(f\"Issue ID: {issue.get('id')}\")\n",
        "        print(f\"Title: {issue.get('title')}\")\n",
        "        print(f\"Description: {issue.get('body', 'No description provided')}\")\n",
        "        print(f\"Labels: {[label['name'] for label in issue.get('labels', [])]}\")\n",
        "        print(f\"Created At: {issue.get('created_at')}\")\n",
        "        print(f\"Comments: {issue.get('comments')}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "else:\n",
        "    print(f\"Failed to fetch data: {response.status_code}, {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEbqYqBRmLCx"
      },
      "source": [
        "## Resources used for this lecture:\n",
        "\n",
        "1.   https://docs.github.com/en/rest?apiVersion=2022-11-28\n",
        "2.   https://github.com/psf/black\n",
        "3.   https://github.com/vercel/vercel\n",
        "4.   https://github.com/trending/\n",
        "5.   https://medium.com/analytics-vidhya/getting-started-with-github-api-dc7057e2834d\n",
        "6.   https://seart-ghs.si.usi.ch/\n",
        "https://blog.apify.com/python-github-api/\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3GQYd-_3lcRw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "codebert",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
